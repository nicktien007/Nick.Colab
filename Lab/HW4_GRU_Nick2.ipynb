{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW4-GRU - Nick2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicktien007/Nick.Colab/blob/main/Lab/HW4_GRU_Nick2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSdQoQ3KoENY"
      },
      "source": [
        "## 連結google 雲端資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQjm63T3kRyl",
        "outputId": "2a30b538-6e6f-446c-ba1b-f0565828a806"
      },
      "source": [
        "# 取得google drive存取權限\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "SYS_DIR = \"/content/drive/MyDrive\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcMSA66lvBzp"
      },
      "source": [
        "## Tapiei_QA data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3PUHmeAdLc6"
      },
      "source": [
        "with open(SYS_DIR+'/Dataset/HW4/Taipei_QA_new_balance.txt') as file:\n",
        "  data = file.readlines()  # 以 \\n 為一個單位讀取"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDl31eVNs8hq",
        "outputId": "b3f5be17-5c3a-4260-f9d2-291da3ee41e6"
      },
      "source": [
        "for i,line in enumerate(data):\n",
        "  if i < 20:\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0,所有權 人 房舍 指定 古蹟 後 獲得 權益\n",
            "\n",
            "0,古蹟 遭受 人為 破壞 政府 處理\n",
            "\n",
            "0,文化局 經管 路段 檔期 使用 情形\n",
            "\n",
            "0,施工 中 疑似 古蹟 建築物 處理\n",
            "\n",
            "0,辦理 文化 藝術 財團法人 基金會 解散\n",
            "\n",
            "0,藝文 補助 件數 申請 件數 項目 限制\n",
            "\n",
            "0,臺北 偶戲館 收費 方式\n",
            "\n",
            "0,士林 官邸 正館 參觀\n",
            "\n",
            "0,辦理 古蹟 土地 容積 移轉\n",
            "\n",
            "0,李國鼎 故居 開放 時間 無須 收取 門票\n",
            "\n",
            "0,臺北市 受 保護 樹木 辦理 修剪\n",
            "\n",
            "0,人有 資格 修復 古蹟\n",
            "\n",
            "0,請問 臺北 表演藝術 中心 設置 地點 定位 規模\n",
            "\n",
            "0,購買 文化局 出版 品\n",
            "\n",
            "0,臺北 偶戲館 地址 開館 時間 資訊\n",
            "\n",
            "0,文化局 押 標金 保證金 繳納 專戶 為何\n",
            "\n",
            "0,古蹟 週邊 開發 行為 限制\n",
            "\n",
            "0,文化局 經管 特定 路段 舉辦 臨時 活動 申請 方式\n",
            "\n",
            "0,紫藤 廬 營業時間 是否 須 收取 門票 聯絡 電話\n",
            "\n",
            "0,林語堂 故居 營業時間 是否 須 收取 門票 聯絡 電話 交通 資訊\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndPF8c9hoDSK",
        "outputId": "dd7a143c-54eb-4393-e29b-b6e74e20abd7"
      },
      "source": [
        "for i, line in enumerate(data):\n",
        "    sp = line.strip().split(',')\n",
        "    \n",
        "    print('label',sp[0])\n",
        "    print('question',sp[1]) \n",
        "    print()\n",
        "    if i == 10 :break "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label 0\n",
            "question 所有權 人 房舍 指定 古蹟 後 獲得 權益\n",
            "\n",
            "label 0\n",
            "question 古蹟 遭受 人為 破壞 政府 處理\n",
            "\n",
            "label 0\n",
            "question 文化局 經管 路段 檔期 使用 情形\n",
            "\n",
            "label 0\n",
            "question 施工 中 疑似 古蹟 建築物 處理\n",
            "\n",
            "label 0\n",
            "question 辦理 文化 藝術 財團法人 基金會 解散\n",
            "\n",
            "label 0\n",
            "question 藝文 補助 件數 申請 件數 項目 限制\n",
            "\n",
            "label 0\n",
            "question 臺北 偶戲館 收費 方式\n",
            "\n",
            "label 0\n",
            "question 士林 官邸 正館 參觀\n",
            "\n",
            "label 0\n",
            "question 辦理 古蹟 土地 容積 移轉\n",
            "\n",
            "label 0\n",
            "question 李國鼎 故居 開放 時間 無須 收取 門票\n",
            "\n",
            "label 0\n",
            "question 臺北市 受 保護 樹木 辦理 修剪\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZI9oRCJfoC_D",
        "outputId": "637b3f14-9807-495e-a2ba-515735283f40"
      },
      "source": [
        "num = 0\n",
        "label = []     \n",
        "for i, line in enumerate(data):\n",
        "  num += 1\n",
        "  sp = line.strip().split(',')\n",
        "  if sp[0] not in label:\n",
        "    label.append(sp[0])\n",
        "print('總數',num)\n",
        "print('類別',len(label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "總數 8195\n",
            "類別 149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_3e3Exe8QqQ"
      },
      "source": [
        "## 資料前處理\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek_k5yC38QWB",
        "outputId": "fa082ab0-5f33-4de0-e1b6-2b9679ceee96"
      },
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for i, line in enumerate(data):\n",
        "  sp = line.strip().split(',')\n",
        "  x.append(sp[1])     #Q\n",
        "  y.append(int(sp[0]))     #A\n",
        "print(x[0],y[0],len(x),len(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "所有權 人 房舍 指定 古蹟 後 獲得 權益 0 8195 8195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsITTMPyQtFH"
      },
      "source": [
        "###input 處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGTEuKADMd-F",
        "outputId": "5077bec2-a591-41c1-daa8-957ac3a1aac4"
      },
      "source": [
        "for i,ele in enumerate(x):\n",
        "  print(ele)\n",
        "  sen_list = (ele.strip().split(' '))\n",
        "  print(sen_list)\n",
        "  print()\n",
        "  if i == 5 :break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "所有權 人 房舍 指定 古蹟 後 獲得 權益\n",
            "['所有權', '人', '房舍', '指定', '古蹟', '後', '獲得', '權益']\n",
            "\n",
            "古蹟 遭受 人為 破壞 政府 處理\n",
            "['古蹟', '遭受', '人為', '破壞', '政府', '處理']\n",
            "\n",
            "文化局 經管 路段 檔期 使用 情形\n",
            "['文化局', '經管', '路段', '檔期', '使用', '情形']\n",
            "\n",
            "施工 中 疑似 古蹟 建築物 處理\n",
            "['施工', '中', '疑似', '古蹟', '建築物', '處理']\n",
            "\n",
            "辦理 文化 藝術 財團法人 基金會 解散\n",
            "['辦理', '文化', '藝術', '財團法人', '基金會', '解散']\n",
            "\n",
            "藝文 補助 件數 申請 件數 項目 限制\n",
            "['藝文', '補助', '件數', '申請', '件數', '項目', '限制']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrVx4aLMIpTQ"
      },
      "source": [
        "from gensim import models\n",
        "model = models.Word2Vec.load(SYS_DIR+'/Model/Wiki/word2vec_wiki_zh.model.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H0LIGI6-JRw",
        "outputId": "62610315-386f-402f-d91d-e9c381912953"
      },
      "source": [
        "#將input斷詞並轉成word2vec向量\n",
        "x_vector = []\n",
        "for i,q in enumerate(x):\n",
        "  word_list = (q.strip().split(' '))\n",
        "  if i == 0:\n",
        "    print(word_list)\n",
        "  tmp=[]\n",
        "  for word in word_list:\n",
        "    try:\n",
        "      tmp.append(model[word])\n",
        "    except:\n",
        "      continue\n",
        "  x_vector.append(tmp)\n",
        "\n",
        "print(len(x_vector))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['所有權', '人', '房舍', '指定', '古蹟', '後', '獲得', '權益']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vj5GilGWORz9",
        "outputId": "6ab41b0d-3eb8-4b75-b118-3408e7e33f7a"
      },
      "source": [
        "#input 長度不一樣須補成相同大小\n",
        "print(len(x_vector[0]),len(x_vector[1]),len(x_vector[2]),len(x_vector[3]))\n",
        "print(len(x_vector[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8 6 6 6\n",
            "400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qZeDzgdbOqZD",
        "outputId": "1e559026-6715-4bd4-e410-e7adada3c410"
      },
      "source": [
        "#找出input最大的長度\n",
        "max_len=0\n",
        "for v in x_vector:\n",
        "  if len(v) > max_len: max_len=len(v)\n",
        "\n",
        "max_len = 60\n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C5GUM_DPM0b",
        "outputId": "4b54958c-be0e-402f-8364-7d2fb08ff185"
      },
      "source": [
        "#將input補齊至最大長度\n",
        "import numpy as np\n",
        "\n",
        "for v in x_vector:\n",
        "  while len(v) < max_len:\n",
        "    v.append(np.zeros(400,dtype=float))\n",
        "print(len(x_vector[0]),len(x_vector[1]),len(x_vector[2]),len(x_vector[3]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60 60 60 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlAKdMWcQ0Wi"
      },
      "source": [
        "###label 處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eq9tWGZQnjF",
        "outputId": "31f0a529-d05d-4926-eb2c-bbd4a31f2ea1"
      },
      "source": [
        "#將label 做 LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "y_Encode = le.fit_transform(y)\n",
        "\n",
        "print(y_Encode[0], y_Encode[100], y_Encode[200])\n",
        "\n",
        "#反轉回文字\n",
        "print(le.inverse_transform([y_Encode[0], y_Encode[100], y_Encode[200]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 1 3\n",
            "[0 1 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELxDDSahTXyj"
      },
      "source": [
        "### 切training data 與 testing data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gtWxcTizSy70",
        "outputId": "6d7c6fe0-37e0-4873-e229-304bc4d8bffd"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_vector, y_Encode, test_size=0.1,random_state = 33)\n",
        "\n",
        "print(len(x_train),len(x_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7375 820\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiSIZOQhlkVs"
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt3dDCY7ieQp"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    \"\"\"\n",
        "    input_size = 400  # input的維度\n",
        "    hidden_dim = 400  # 隱藏層維度\n",
        "    num_layers = 1    # GRU迭代次數\n",
        "    label_num = 149   # 總Label數量\n",
        "    max_len = max_len # 句子最大長度->60\n",
        "    batch_size = 1    # batch_size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_dim, num_layers, output_dim, batch_size, max_len):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.batch_size = batch_size\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.gru = nn.GRU(input_size, hidden_dim, num_layers=1, batch_first=True)  # input_size,  隱藏層維度\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)  # 將句向量經過一層liner判斷類別\n",
        "        \n",
        "        # self.fc = nn.Sequential(\n",
        "        #     nn.Linear(hidden_dim, hidden_dim),\n",
        "        #     nn.Dropout(0.2),\n",
        "        #     # torch.nn.ReLU(),\n",
        "        #     nn.Linear(hidden_dim, output_dim)\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):  \n",
        "        gru_output, hidden = self.gru(x, None)\n",
        "        sen_vec_output = gru_output[:, -1, :]  # 只使用最後的输出做為句向量\n",
        "        liner_output = self.fc(sen_vec_output)\n",
        "\n",
        "        # liner_output = self.fc(self.dropout(sen_vec_output))\n",
        "\n",
        "        return liner_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGcCIx7Pi9G4"
      },
      "source": [
        "import logging\n",
        "\n",
        "input_size = 400  # input的維度\n",
        "hidden_dim = 400  # 隱藏層維度\n",
        "num_layers = 1  # GRU迭代次數\n",
        "label_num = 149  # 總Label數量\n",
        "max_len = 60  # 句子最大長度\n",
        "batch_size = 1  # batch_size\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "class TrainModel:\n",
        "    def __init__(self, epoches=10):\n",
        "        self.model = GRU(input_size=input_size,\n",
        "                         hidden_dim=hidden_dim,\n",
        "                         num_layers=num_layers,\n",
        "                         output_dim=label_num,\n",
        "                         batch_size=batch_size,\n",
        "                         max_len=max_len)\n",
        "        self.model.to(device)\n",
        "        self.epoches = epoches\n",
        "        logging.info(self.model)\n",
        "\n",
        "    def train(self, x_train_set, y_train_set, x_test_set, y_test_set):\n",
        "        loss_func = nn.CrossEntropyLoss().to(device)\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.001)\n",
        "\n",
        "        for epoch in range(self.epoches):\n",
        "            self.model.train()\n",
        "            total_loss = 0\n",
        "            correct = 0\n",
        "            for x in range(len(x_train_set)):  \n",
        "                q = x_train_set[x]\n",
        "                a = y_train_set[x]\n",
        "\n",
        "                q_tensor = torch.tensor([q], dtype=torch.float, device=device)\n",
        "                a_tensor = torch.tensor([a], dtype=torch.long, device=device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                pred = self.model(q_tensor)  # [batch, out_dim]\n",
        "                # print(\"torch.argmax(pred).item() = \",torch.argmax(pred).item())\n",
        "                loss = loss_func(pred, a_tensor)\n",
        "                loss.backward()\n",
        "                total_loss += loss\n",
        "                if torch.argmax(pred).item() == a:\n",
        "                    correct += 1\n",
        "                optimizer.step()\n",
        "\n",
        "            logging.info(\"Training: in epoch {} loss {}, accuracy is {}%\".format(epoch, total_loss / len(x_train_set),correct / len(x_train_set) * 100.0))\n",
        "            self.evaluate(x_test_set, y_test_set)\n",
        "\n",
        "    def evaluate(self, x_test_set, y_test_set):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():  # 評估時不進行梯度計算\n",
        "            correct = 0\n",
        "            for x in range(len(x_test_set)):  \n",
        "                q = x_test_set[x]\n",
        "                a = y_test_set[x]\n",
        "                q_tensor = torch.tensor([q], dtype=torch.float, device=device)\n",
        "\n",
        "                pred = self.model(q_tensor)\n",
        "                if torch.argmax(pred).item() == a:\n",
        "                    correct += 1\n",
        "\n",
        "            logging.info('Evaluating: test accuracy is {}%'.format(correct / len(x_test_set) * 100.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqgwl7_CjidM",
        "outputId": "0d3b8f0f-0a66-4fc4-8d6e-9a72bc8cafe4"
      },
      "source": [
        "logging.info(\"start train!!\")\n",
        "m = TrainModel(12)\n",
        "m.train(x_train, y_train, x_test, y_test)\n",
        "logging.info(\"end train!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-26 08:07:12,409 : INFO : start train!!\n",
            "2020-11-26 08:07:12,427 : INFO : GRU(\n",
            "  (gru): GRU(400, 400, batch_first=True)\n",
            "  (fc): Linear(in_features=400, out_features=149, bias=True)\n",
            ")\n",
            "2020-11-26 08:07:58,501 : INFO : Training: in epoch 0 loss 5.0312371253967285, accuracy is 0.7728813559322034%\n",
            "2020-11-26 08:08:01,290 : INFO : Evaluating: test accuracy is 0.3658536585365854%\n",
            "2020-11-26 08:08:47,477 : INFO : Training: in epoch 1 loss 4.462423324584961, accuracy is 11.959322033898305%\n",
            "2020-11-26 08:08:50,286 : INFO : Evaluating: test accuracy is 41.70731707317073%\n",
            "2020-11-26 08:09:36,968 : INFO : Training: in epoch 2 loss 1.5999667644500732, accuracy is 63.010169491525424%\n",
            "2020-11-26 08:09:39,783 : INFO : Evaluating: test accuracy is 67.07317073170732%\n",
            "2020-11-26 08:10:26,413 : INFO : Training: in epoch 3 loss 0.7175881266593933, accuracy is 81.54576271186441%\n",
            "2020-11-26 08:10:29,224 : INFO : Evaluating: test accuracy is 74.7560975609756%\n",
            "2020-11-26 08:11:15,857 : INFO : Training: in epoch 4 loss 0.3962251842021942, accuracy is 89.45084745762712%\n",
            "2020-11-26 08:11:18,682 : INFO : Evaluating: test accuracy is 76.34146341463415%\n",
            "2020-11-26 08:12:05,391 : INFO : Training: in epoch 5 loss 0.2728917598724365, accuracy is 92.28474576271186%\n",
            "2020-11-26 08:12:08,297 : INFO : Evaluating: test accuracy is 77.92682926829269%\n",
            "2020-11-26 08:12:55,586 : INFO : Training: in epoch 6 loss 0.20833925902843475, accuracy is 94.4813559322034%\n",
            "2020-11-26 08:12:58,413 : INFO : Evaluating: test accuracy is 77.4390243902439%\n",
            "2020-11-26 08:13:44,512 : INFO : Training: in epoch 7 loss 0.19839701056480408, accuracy is 94.30508474576271%\n",
            "2020-11-26 08:13:47,302 : INFO : Evaluating: test accuracy is 77.5609756097561%\n",
            "2020-11-26 08:14:33,515 : INFO : Training: in epoch 8 loss 0.14477702975273132, accuracy is 96.27118644067797%\n",
            "2020-11-26 08:14:36,285 : INFO : Evaluating: test accuracy is 77.07317073170732%\n",
            "2020-11-26 08:15:22,211 : INFO : Training: in epoch 9 loss 0.1590593308210373, accuracy is 95.41694915254237%\n",
            "2020-11-26 08:15:25,014 : INFO : Evaluating: test accuracy is 78.53658536585367%\n",
            "2020-11-26 08:16:10,761 : INFO : Training: in epoch 10 loss 0.13234758377075195, accuracy is 96.27118644067797%\n",
            "2020-11-26 08:16:13,560 : INFO : Evaluating: test accuracy is 79.02439024390245%\n",
            "2020-11-26 08:16:59,319 : INFO : Training: in epoch 11 loss 0.12426427751779556, accuracy is 96.51525423728813%\n",
            "2020-11-26 08:17:02,087 : INFO : Evaluating: test accuracy is 76.70731707317073%\n",
            "2020-11-26 08:17:02,125 : INFO : end train!!\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}