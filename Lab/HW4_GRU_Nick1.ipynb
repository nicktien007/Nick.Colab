{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "HW4-GRU - Nick1",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nicktien007/Nick.Colab/blob/main/Lab/HW4_GRU_Nick1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSdQoQ3KoENY"
      },
      "source": [
        "## 連結google 雲端資料"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQjm63T3kRyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c121bed-8c35-4427-c036-3dfcd8967fa0"
      },
      "source": [
        "# 取得google drive存取權限\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcMSA66lvBzp"
      },
      "source": [
        "## Tapiei_QA data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3PUHmeAdLc6"
      },
      "source": [
        "\n",
        "with open('drive/Shared drives/在職新手村/Data/Taipei_QA_new.txt') as file:\n",
        "  data = file.readlines()  # 以 \\n 為一個單位讀取"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDl31eVNs8hq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70abb9c-8555-4204-d36a-6f0fe180e7ca"
      },
      "source": [
        "for i,line in enumerate(data):\n",
        "  if i < 20:\n",
        "    print(line)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "臺北市政府文化局 2018臺北藝術節FAQ\n",
            "\n",
            "臺北市政府文化局 臺北市信義區Neo19大樓後方人行道後場使用作業通告(107/06/03-05)\n",
            "\n",
            "臺北市政府文化局 2018台北電影節FAQ\n",
            "\n",
            "臺北市政府文化局 臺灣新文化運動紀念館位置與聯絡方式\n",
            "\n",
            "臺北市政府文化局 臺灣新文化運動紀念館開館及參觀時間?\n",
            "\n",
            "臺北市政府文化局 2018臺北兒童藝術節FAQ\n",
            "\n",
            "臺北市政府文化局 藝文補助之申請時間及計畫執行時間\n",
            "\n",
            "臺北市政府文化局 新芳春茶行地點、開放時間、聯絡方式\n",
            "\n",
            "臺北市政府文化局 如何前往松山文創園區\n",
            "\n",
            "臺北市政府文化局 被指定古蹟之建築物要符合何種條件，才能辦理容積移轉？\n",
            "\n",
            "臺北市政府文化局 所有權人接獲古蹟公告後，如不服指定程序該如何處理？\n",
            "\n",
            "臺北市政府文化局 臺北市政府古蹟歷史建築紀念建築聚落建築群考古遺址史蹟及文化景觀審議會如何組成？\n",
            "\n",
            "臺北市政府文化局 如何申請「古蹟」指定、「歷史建築」登錄？「古蹟」指定、「歷史建築」登錄的程序為何？\n",
            "\n",
            "臺北市政府文化局 錢穆故居營業時間？是否須收取門票？聯絡電話？交通資訊？\n",
            "\n",
            "臺北市政府文化局 林語堂故居營業時間？是否須收取門票？聯絡電話？交通資訊？\n",
            "\n",
            "臺北市政府文化局 臺北二二八紀念館開館及參觀時間?交通方式?\n",
            "\n",
            "臺北市政府文化局 所有權人的房舍被指定為古蹟後，可以獲得什麼權益？\n",
            "\n",
            "臺北市政府文化局 施工中，如發現疑似古蹟之建築物該如何處理？\n",
            "\n",
            "臺北市政府文化局 我的家鄰近古蹟，我的權益會不會受損？\n",
            "\n",
            "臺北市政府文化局 如何解除「古蹟」或「歷史建築」之身分？\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndPF8c9hoDSK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35ab4ac0-8ab2-4652-86ba-ab5a6df261c7"
      },
      "source": [
        "for i, line in enumerate(data):\n",
        "    sp = line.strip().split(' ')\n",
        "    \n",
        "    print('label',sp[0])\n",
        "    print('question',sp[1]) \n",
        "    print()\n",
        "    if i == 10 :break "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "label 臺北市政府文化局\n",
            "question 2018臺北藝術節FAQ\n",
            "\n",
            "label 臺北市政府文化局\n",
            "question 臺北市信義區Neo19大樓後方人行道後場使用作業通告(107/06/03-05)\n",
            "\n",
            "label 臺北市政府文化局\n",
            "question 2018台北電影節FAQ\n",
            "\n",
            "label 臺北市政府文化局\n",
            "question 臺灣新文化運動紀念館位置與聯絡方式\n",
            "\n",
            "label 臺北市政府文化局\n",
            "question 臺灣新文化運動紀念館開館及參觀時間?\n",
            "\n",
            "label 臺北市政府文化局\n",
            "question 2018臺北兒童藝術節FAQ\n",
            "\n",
            "label 臺北市政府文化局\n",
            "question 藝文補助之申請時間及計畫執行時間\n",
            "\n",
            "label 臺北市政府文化局\n",
            "question 新芳春茶行地點、開放時間、聯絡方式\n",
            "\n",
            "label 臺北市政府文化局\n",
            "question 如何前往松山文創園區\n",
            "\n",
            "label 臺北市政府文化局\n",
            "question 被指定古蹟之建築物要符合何種條件，才能辦理容積移轉？\n",
            "\n",
            "label 臺北市政府文化局\n",
            "question 所有權人接獲古蹟公告後，如不服指定程序該如何處理？\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZI9oRCJfoC_D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6bede51-347c-4e55-854a-0c162cb281df"
      },
      "source": [
        "num = 0\n",
        "label = []     \n",
        "for i, line in enumerate(data):\n",
        "  num += 1\n",
        "  sp = line.strip().split(' ')\n",
        "  if sp[0] not in label:\n",
        "    label.append(sp[0])\n",
        "print('總數',num)\n",
        "print('類別',len(label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "總數 7986\n",
            "類別 149\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_3e3Exe8QqQ"
      },
      "source": [
        "## 資料前處理\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ek_k5yC38QWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce4ec5c-8c7d-4737-885f-1a97ae9f51d9"
      },
      "source": [
        "x=[]\n",
        "y=[]\n",
        "for i, line in enumerate(data):\n",
        "  sp = line.strip().split(' ')\n",
        "  x.append(sp[1])     #Q\n",
        "  y.append(sp[0])     #A\n",
        "print(x[0],y[0],len(x),len(y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018臺北藝術節FAQ 臺北市政府文化局 7986 7986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsITTMPyQtFH"
      },
      "source": [
        "###input 處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gbr5NY5sJRZ0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28d9d8f-bb5c-4111-cefd-cd81654755b2"
      },
      "source": [
        "#使用實驗室api斷詞 https://github.com/UDICatNCHU/UdicOpenData\n",
        "!pip3 install udicOpenData\n",
        "from udicOpenData.dictionary import *\n",
        "from udicOpenData.stopwords import *"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting udicOpenData\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/54/b459a4865de39c09e0a4d5796f47cc1c46a2ef04c24bdf698ed952440886/udicOpenData-2.4.tar.gz (17.8MB)\n",
            "\u001b[K     |████████████████████████████████| 17.8MB 205kB/s \n",
            "\u001b[?25hRequirement already satisfied: jieba in /usr/local/lib/python3.6/dist-packages (from udicOpenData) (0.42.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from udicOpenData) (3.2.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from udicOpenData) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->udicOpenData) (1.15.0)\n",
            "Building wheels for collected packages: udicOpenData\n",
            "  Building wheel for udicOpenData (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for udicOpenData: filename=udicOpenData-2.4-cp36-none-any.whl size=18094429 sha256=a6fec79120c1d52976eb52934eb92199adde0c1917a8e73029ec1940e950585b\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/5d/fc/4ed48af0b3c24ff9c4cb9b868680540afb2edcebbcd65abd43\n",
            "Successfully built udicOpenData\n",
            "Installing collected packages: udicOpenData\n",
            "Successfully installed udicOpenData-2.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.812 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGTEuKADMd-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc697d4-406a-4798-d68f-2aa9164bf787"
      },
      "source": [
        "for i,ele in enumerate(x):\n",
        "  print(ele)\n",
        "  sen_list = list(rmsw(ele))\n",
        "  print(sen_list)\n",
        "  print()\n",
        "  if i == 5 :break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018臺北藝術節FAQ\n",
            "['臺北', '藝術節', 'FAQ']\n",
            "\n",
            "臺北市信義區Neo19大樓後方人行道後場使用作業通告(107/06/03-05)\n",
            "['臺北市', '信義區', 'Neo', '大樓', '後方', '人行道', '後場', '使用', '作業', '通告']\n",
            "\n",
            "2018台北電影節FAQ\n",
            "['台北', '電影節', 'FAQ']\n",
            "\n",
            "臺灣新文化運動紀念館位置與聯絡方式\n",
            "['臺灣', '新文化運動', '紀念館', '位置', '聯絡', '方式']\n",
            "\n",
            "臺灣新文化運動紀念館開館及參觀時間?\n",
            "['臺灣', '新文化運動', '紀念館', '開館', '參觀', '時間']\n",
            "\n",
            "2018臺北兒童藝術節FAQ\n",
            "['臺北', '兒童', '藝術節', 'FAQ']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrVx4aLMIpTQ"
      },
      "source": [
        "from gensim import models\n",
        "model = models.Word2Vec.load('/content/drive/Shared drives/在職新手村/model/word2vec_wiki_zh.model.bin')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9H0LIGI6-JRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f5f0bc-79c4-4b7f-c107-bc47bba05702"
      },
      "source": [
        "#將input斷詞並轉成word2vec向量\n",
        "x_vector = []\n",
        "for i,q in enumerate(x):\n",
        "  word_list = list(rmsw(q))\n",
        "  tmp=[]\n",
        "  for word in word_list:\n",
        "    try:\n",
        "      tmp.append(model[word])\n",
        "    except:\n",
        "      continue\n",
        "  x_vector.append(tmp)\n",
        "  \n",
        "#   print(len(tmp),len(tmp[0]))\n",
        "#   print(tmp)\n",
        "#   break\n",
        "\n",
        "print(len(x_vector))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7986\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj5GilGWORz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c396c348-c7fb-4fe5-8505-42428daf0def"
      },
      "source": [
        "#input 長度不一樣須補成相同大小\n",
        "print(len(x_vector[0]),len(x_vector[1]),len(x_vector[2]),len(x_vector[3]))\n",
        "print(len(x_vector[0][0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 9 1 6\n",
            "400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZeDzgdbOqZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ab6e602-5e01-4cff-eec3-459e19d8eab2"
      },
      "source": [
        "#找出input最大的長度\n",
        "max_len=0\n",
        "for v in x_vector:\n",
        "  if len(v) > max_len: max_len=len(v)\n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7C5GUM_DPM0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac6f331d-68af-4d84-8d62-d6863f3b73f3"
      },
      "source": [
        "#將input補齊至最大長度\n",
        "import numpy as np\n",
        "\n",
        "for v in x_vector:\n",
        "  while len(v) < max_len:\n",
        "    v.append(np.zeros(400,dtype=float))\n",
        "print(len(x_vector[0]),len(x_vector[1]),len(x_vector[2]),len(x_vector[3]))\n",
        "# print(x_vector[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60 60 60 60\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlAKdMWcQ0Wi"
      },
      "source": [
        "###label 處理"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eq9tWGZQnjF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48110a92-5dfb-43be-82da-073f3460d494"
      },
      "source": [
        "#將label 做 LabelEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "y_Encode = le.fit_transform(y)\n",
        "print(y_Encode[0], y_Encode[100], y_Encode[200])\n",
        "\n",
        "#反轉回文字\n",
        "print(le.inverse_transform([y_Encode[0], y_Encode[100], y_Encode[200]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78 100 110\n",
            "['臺北市政府文化局' '臺北市政府產業發展局科技產業服務中心' '臺北市政府社會局身心障礙者福利科']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELxDDSahTXyj"
      },
      "source": [
        "### 切training data 與 testing data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtWxcTizSy70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84e3086f-37e9-4d2a-f1df-af33933c4432"
      },
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_vector, y_Encode, test_size=0.1,random_state = 88)\n",
        "\n",
        "print(len(x_train),len(x_test))\n",
        "print(type(x_train))\n",
        "\n",
        "# _x = torch.Tensor(x_train)\n",
        "# print(type(_x))\n",
        "# print(_x[0].size())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7187 799\n",
            "<class 'list'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiSIZOQhlkVs"
      },
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bt3dDCY7ieQp"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class GRU(nn.Module):\n",
        "    \"\"\"\n",
        "    input_size = 400  # input的維度\n",
        "    hidden_dim = 400  # 隱藏層維度\n",
        "    num_layers = 1    # GRU迭代次數\n",
        "    label_num = 149   # 總Label數量\n",
        "    max_len = max_len # 句子最大長度->60\n",
        "    batch_size = 1    # batch_size\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_size, hidden_dim, num_layers, output_dim, batch_size, max_len):\n",
        "        super(GRU, self).__init__()\n",
        "\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "        self.input_size = input_size\n",
        "        self.batch_size = batch_size\n",
        "        self.max_len = max_len\n",
        "\n",
        "        self.gru = nn.GRU(input_size, hidden_dim, num_layers=self.num_layers, batch_first=True)  # input_size,  隱藏層維度\n",
        "        # self.dropout = nn.Dropout(p=0.1)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)  # 將句向量經過一層liner判斷類別\n",
        "        \n",
        "        # self.fc = nn.Sequential(\n",
        "        #     nn.Linear(hidden_dim, hidden_dim),\n",
        "        #     nn.Dropout(0.3),\n",
        "        #     # torch.nn.ReLU(),\n",
        "        #     nn.Linear(hidden_dim, output_dim)\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input shape:B * S -> S * B\n",
        "\n",
        "        # input = x.t()\n",
        "        # embedding = self.embedding(input)\n",
        "\n",
        "        # h0 = self.__init__hidden()  # 隱藏層h0\n",
        "\n",
        "        # gru_input = pack_padded_sequence(embedding, self.input_size )\n",
        "\n",
        "\n",
        "        # gru_input = t.randn(self.batch_size, self.max_len, self.input_size)  # batch_size, 句子最大長度, input的維度\n",
        "        gru_output, hidden = self.gru(x, None)\n",
        "        sen_vec_output = gru_output[:, -1, :]  # 只使用最後的输出做為句向量\n",
        "        liner_output = self.fc(sen_vec_output)\n",
        "\n",
        "        # liner_output = self.fc(self.dropout(sen_vec_output))\n",
        "\n",
        "        return liner_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGcCIx7Pi9G4"
      },
      "source": [
        "import logging\n",
        "\n",
        "input_size = 400  # input的維度\n",
        "hidden_dim = 400  # 隱藏層維度\n",
        "num_layers = 1  # GRU迭代次數\n",
        "label_num = 149  # 總Label數量\n",
        "max_len = 60  # 句子最大長度\n",
        "batch_size = 1  # batch_size\n",
        "device = torch.device('cuda:0')\n",
        "\n",
        "class TrainModel:\n",
        "    def __init__(self, epoches=10):\n",
        "        self.model = GRU(input_size=input_size,\n",
        "                         hidden_dim=hidden_dim,\n",
        "                         num_layers=num_layers,\n",
        "                         output_dim=label_num,\n",
        "                         batch_size=batch_size,\n",
        "                         max_len=max_len)\n",
        "        self.model.to(device)\n",
        "        self.epoches = epoches\n",
        "        logging.info(self.model)\n",
        "\n",
        "    def train(self, x_train_set, y_train_set, x_test_set, y_test_set):\n",
        "        loss_func = nn.CrossEntropyLoss().to(device)\n",
        "        optimizer = torch.optim.Adam(self.model.parameters(), lr=0.003)\n",
        "\n",
        "        for epoch in range(self.epoches):\n",
        "            self.model.train()\n",
        "            total_loss = 0\n",
        "            correct = 0\n",
        "            for x in range(len(x_train_set)):  \n",
        "                q = x_train_set[x]\n",
        "                a = y_train_set[x]\n",
        "\n",
        "                q_tensor = torch.tensor([q], dtype=torch.float, device=device)\n",
        "                a_tensor = torch.tensor([a], dtype=torch.long, device=device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                pred = self.model(q_tensor)  # [batch, out_dim]\n",
        "                # print(\"torch.argmax(pred).item() = \",torch.argmax(pred).item())\n",
        "                loss = loss_func(pred, a_tensor)\n",
        "                loss.backward()\n",
        "                total_loss += loss\n",
        "                if torch.argmax(pred).item() == a:\n",
        "                    correct += 1\n",
        "                optimizer.step()\n",
        "\n",
        "            logging.info(\"Training: in epoch {} loss {}, accuracy is {}\".format(epoch, total_loss / len(x_train_set),correct / len(x_train_set) * 100.0))\n",
        "            self.evaluate(x_test_set, y_test_set)\n",
        "\n",
        "    def evaluate(self, x_test_set, y_test_set):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():  # 評估時不進行梯度計算\n",
        "            correct = 0\n",
        "            for x in range(len(x_test_set)):  \n",
        "                q = x_test_set[x]\n",
        "                a = y_test_set[x]\n",
        "                q_tensor = torch.tensor([q], dtype=torch.float, device=device)\n",
        "\n",
        "                pred = self.model(q_tensor)\n",
        "                if torch.argmax(pred).item() == a:\n",
        "                    correct += 1\n",
        "\n",
        "            logging.info('Evaluating: test accuracy is {}%'.format(correct / len(x_test_set) * 100.0))\n",
        "            print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sqgwl7_CjidM",
        "outputId": "45c0a30f-cd3d-4d1b-ad93-34b5b9104c06"
      },
      "source": [
        "m = TrainModel(20)\n",
        "m.train(x_train, y_train, x_test, y_test)\n",
        "print(\"end train!!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-11-25 14:53:03,565 : INFO : GRU(\n",
            "  (gru): GRU(400, 400, batch_first=True)\n",
            "  (fc): Linear(in_features=400, out_features=149, bias=True)\n",
            ")\n",
            "2020-11-25 14:53:51,680 : INFO : Training: in epoch 0 loss 4.571261882781982, accuracy is 10.546820648392933\n",
            "2020-11-25 14:53:54,620 : INFO : Evaluating: test accuracy is 32.91614518147685%\n",
            "2020-11-25 14:54:42,219 : INFO : Training: in epoch 1 loss 2.587568521499634, accuracy is 40.823709475441774\n",
            "2020-11-25 14:54:45,103 : INFO : Evaluating: test accuracy is 47.18397997496871%\n",
            "2020-11-25 14:55:33,115 : INFO : Training: in epoch 2 loss 1.8782691955566406, accuracy is 53.7219980520384\n",
            "2020-11-25 14:55:36,030 : INFO : Evaluating: test accuracy is 50.06257822277848%\n",
            "2020-11-25 14:56:23,446 : INFO : Training: in epoch 3 loss 1.5190808773040771, accuracy is 60.84597189369695\n",
            "2020-11-25 14:56:26,342 : INFO : Evaluating: test accuracy is 54.56821026282853%\n",
            "2020-11-25 14:57:13,884 : INFO : Training: in epoch 4 loss 1.1218072175979614, accuracy is 69.75093919577014\n",
            "2020-11-25 14:57:16,819 : INFO : Evaluating: test accuracy is 52.31539424280351%\n",
            "2020-11-25 14:58:04,350 : INFO : Training: in epoch 5 loss 1.0657354593276978, accuracy is 70.22401558369278\n",
            "2020-11-25 14:58:07,241 : INFO : Evaluating: test accuracy is 54.31789737171464%\n",
            "2020-11-25 14:58:54,741 : INFO : Training: in epoch 6 loss 1.0058115720748901, accuracy is 72.77027967162934\n",
            "2020-11-25 14:58:57,649 : INFO : Evaluating: test accuracy is 53.81727158948686%\n",
            "2020-11-25 14:59:45,331 : INFO : Training: in epoch 7 loss 0.9793834090232849, accuracy is 72.77027967162934\n",
            "2020-11-25 14:59:48,237 : INFO : Evaluating: test accuracy is 54.56821026282853%\n",
            "2020-11-25 15:00:36,028 : INFO : Training: in epoch 8 loss 0.930617094039917, accuracy is 73.8555725615695\n",
            "2020-11-25 15:00:38,950 : INFO : Evaluating: test accuracy is 53.31664580725908%\n",
            "2020-11-25 15:01:26,236 : INFO : Training: in epoch 9 loss 0.8697086572647095, accuracy is 75.40002782802281\n",
            "2020-11-25 15:01:29,141 : INFO : Evaluating: test accuracy is 54.192740926157704%\n",
            "2020-11-25 15:02:16,236 : INFO : Training: in epoch 10 loss 0.8192639350891113, accuracy is 76.42966467232503\n",
            "2020-11-25 15:02:19,103 : INFO : Evaluating: test accuracy is 53.56695869837297%\n",
            "2020-11-25 15:03:06,155 : INFO : Training: in epoch 11 loss 0.7828141450881958, accuracy is 77.66801168776959\n",
            "2020-11-25 15:03:09,037 : INFO : Evaluating: test accuracy is 54.31789737171464%\n",
            "2020-11-25 15:03:56,550 : INFO : Training: in epoch 12 loss 0.8187233805656433, accuracy is 77.16710727702797\n",
            "2020-11-25 15:03:59,425 : INFO : Evaluating: test accuracy is 54.192740926157704%\n",
            "2020-11-25 15:04:46,407 : INFO : Training: in epoch 13 loss 0.7421022653579712, accuracy is 79.01767079449004\n",
            "2020-11-25 15:04:49,296 : INFO : Evaluating: test accuracy is 53.56695869837297%\n",
            "2020-11-25 15:05:36,850 : INFO : Training: in epoch 14 loss 0.5634213089942932, accuracy is 83.52581049116459\n",
            "2020-11-25 15:05:39,725 : INFO : Evaluating: test accuracy is 52.690863579474346%\n",
            "2020-11-25 15:06:26,809 : INFO : Training: in epoch 15 loss 0.5900879502296448, accuracy is 83.06664811465146\n",
            "2020-11-25 15:06:29,679 : INFO : Evaluating: test accuracy is 53.191489361702125%\n",
            "2020-11-25 15:07:16,594 : INFO : Training: in epoch 16 loss 0.6923763155937195, accuracy is 81.1604285515514\n",
            "2020-11-25 15:07:19,482 : INFO : Evaluating: test accuracy is 53.44180225281602%\n",
            "2020-11-25 15:08:06,532 : INFO : Training: in epoch 17 loss 0.7010928988456726, accuracy is 80.57604007235287\n",
            "2020-11-25 15:08:09,400 : INFO : Evaluating: test accuracy is 51.56445556946183%\n",
            "2020-11-25 15:08:56,750 : INFO : Training: in epoch 18 loss 0.7245301008224487, accuracy is 80.42298594684848\n",
            "2020-11-25 15:08:59,617 : INFO : Evaluating: test accuracy is 52.31539424280351%\n",
            "2020-11-25 15:09:46,531 : INFO : Training: in epoch 19 loss 0.7547096610069275, accuracy is 79.7411993877835\n",
            "2020-11-25 15:09:49,419 : INFO : Evaluating: test accuracy is 50.81351689612015%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "end train!!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}